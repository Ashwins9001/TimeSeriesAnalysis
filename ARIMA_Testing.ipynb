{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ARIMA-Testing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX-lHgDH1eQG"
      },
      "source": [
        "AutoRegression (AR), Integrated (I), Moving Average (MA) components form ARIMA model. \n",
        "\n",
        "AR part indicates observed valued is dependent on lagged values. \n",
        "\n",
        "MA component indicates relationship exists between current value and linear combination of prior stochastic terms. Each stochastic term is sampled from white noise which is a stationary random process that samples from a normal distribution with mean zero. Note MA in ARIMA isn't the same as the MA filter which smooths out a time series. Each stochastic term from white noise is independent and represents random shocks or error terms in the process (data we cannot account for). \n",
        "\n",
        "I component refers to number of differencing levels required to make series stationary to apply AR, MA.\n",
        "\n",
        "Non-seasonal ARIMA models denoted ARIMA(p, d, q) where p, d, q are non-negative integers. Where p refers to order of AR, d is differencing levels needed, and q is order of MA. \n",
        "\n",
        "ARIMA models are a additivite combination of each component and solving for the parameters of each component allows for forecasting following time point. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlKBz9tj5ubB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVrbV5vG-wKG"
      },
      "source": [
        "Denote observed outcomes by O, and the set of parameters that describe some stochastic process by theta. Therefore to compute probability of an event, do: P(O | theta). Meaning given some parameters we can figure out the probability of observing O. \n",
        "\n",
        "However in reality it is the opposite, where we are given observations O and want to estimate the parameters to obtain a model to use for forecasting or prediction. In that case, we want to choose parameters that maximize the likelihood that we get observations O. In other words:\n",
        "\n",
        "L(theta | O) = P(O | theta)\n",
        "\n",
        "By fixing the random variables to distinct values (representing observations), can solve for parameters (theta) through maximum likelihood estimation (MLE). MLE is analagous to the loss function used in machine learning which performs a very similar analysis. \n",
        "\n",
        "General MLE is an optimization problem that aims to produce solution equations that would work for any specifications of the random variables.\n",
        "\n",
        "The same idea applies across both discrete and continuous space, in the continous space however we would use a probability density function, f(O | theta) rather than a distinct probability (due to probability laws involving sets). \n",
        "\n",
        "When evaluating and selecting ARIMA models by grid search, use AIC which measures number of parameters used and MLE to compute, compare many ARIMA models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFIG9BXgAcjD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}